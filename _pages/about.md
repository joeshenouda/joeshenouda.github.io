---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am currently a Ph.D. candidate in the department of Electrical and Computer Engineering at the [University of Wisconsin-Madison](https://www.wisc.edu/) advised by [Prof. Kangwook Lee](https://kangwooklee.com/) and [Prof. Robert D. Nowak](https://nowak.ece.wisc.edu/). Before coming to Madison I received my B.S. in Electrical and Computer Engineering from [Rutgers University](https://www.rutgers.edu/) and was advised by [Prof. Waheed U. Bajwa](http://www.inspirelab.us/people/).

For more about my experiences check out my [CV](/files/Shenouda_Joseph_CV.pdf).

My research interests are in both the theoretical and practical aspects of
signal processing and machine learning methods. Most recently I've been
interested in understanding deep neural networks and the effect of explicit
regularization, such as weight decay.

## Preprints
<ins>Variation Spaces for Multi-Output Neural Networks: Insights on Multi-Task Learning and Network Compression</ins>
<br>
**Joseph Shenouda**, Rahul Parhi, Kangwook Lee, Robert D. Nowak.
<br>
In Review
<br>
[[arXiv]](https://arxiv.org/abs/2305.16534)



<ins>PathProx: A Proximal Gradient Algorithm for Weight Decay Regularized Deep Neural Networks</ins>
<br>
Liu Yang, Jifan Zhang, **Joseph Shenouda**, Dimitris Papailiopoulos, Kangwook Lee, Robert D. Nowak.
<br>
In Review
<br>
[[arXiv]](https://arxiv.org/abs/2210.03069) [[code]](https://github.com/Leiay/PathProx/tree/main)

## Publications
<ins>A Representer Theorem for Vector-Valued Neural Networks: Insights on Weight Decay Training and Widths of Deep Neural Networks</ins>
<br>
**Joseph Shenouda**, Rahul Parhi, Kangwook Lee, Robert D. Nowak. 
<br>
*International Conference on Machine Learning (ICML) Duality Principles for Modern ML Workshop* (**contributed talk**)
<br>
[[video]](https://slideslive.com/39006552/a-representer-theorem-for-vectorvalued-neural-networks-insights-on-weight-decay-regularization-and-widths-of-dnns?ref=speaker-22889)

<ins>A Continuous Transform for Localized Ridgelets</ins>
<br>
**Joseph Shenouda**, Rahul Parhi, Robert D. Nowak.
<br>
*Sampling Theory and Applications Conference (SampTA) 2023* (**contributed talk**)
<br>
[[paper]](https://openreview.net/pdf?id=bxvnMaTbarp)

<ins>A Guide to Computational Reproducibility in Signal Processing and Machine Learning</ins>
<br>
**Joseph Shenouda** and Waheed U. Bajwa.
<br>
*IEEE Signal Processing Magazine 2023*
<br>
[[paper]](https://arxiv.org/abs/2108.12383).

<ins>A Better Way to Decay: Proximal Gradient Training Algorithms for Neural Nets</ins>
<br>
Liu Yang, Jifan Zhang, **Joseph Shenouda**, Dimitris Papailiopoulos, Kangwook Lee, Robert D. Nowak.
<br>
*Neural Information Processing Systems (NeurIPS) OPT-ML Workshop 2022*
<br>
[[paper]](https://openreview.net/forum?id=4y1xh8jClhC)

 

